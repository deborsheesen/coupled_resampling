{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook has all the functions for the Lorenz63 model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calling libraries:\n",
    "from __future__ import division\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import time\n",
    "from scipy.stats import norm, uniform, bernoulli\n",
    "from scipy.linalg import sqrtm \n",
    "import math \n",
    "from resampling_functions import resample, systematic_resampling\n",
    "import scipy\n",
    "import multiprocessing as mp\n",
    "import parmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Here $W$ is $N$ iid copies of $N(0,1)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def propagate_Lorenz63(X, W, dt, delta, theta) :\n",
    "    \"\"\"\n",
    "    usual: 3D Lorenz model + multiplicative noise\n",
    "    compute one step forward, usual Euler-Maruyama discretization\n",
    "    \"\"\"\n",
    "    sigma = theta[0]\n",
    "    rho   = theta[1]\n",
    "    beta  = theta[2]\n",
    "    noise_intensity = theta[3]\n",
    "    #ODE forward + noise\n",
    "    N = np.shape(X)[1]\n",
    "    sqdt = np.sqrt(dt)\n",
    "\n",
    "    for i in range( int(delta/dt) ) :\n",
    "        xx = np.zeros(( 3, N ))\n",
    "        xx[0,:] = X[0,:] + dt*sigma*(X[1,:] - X[0,:]) + noise_intensity*X[0,:]*sqdt*W[i,:]\n",
    "        xx[1,:] = X[1,:] + dt*(X[0,:]*(rho - X[2,:]) - X[1,:]) + noise_intensity*X[1,:]*sqdt*W[i,:]\n",
    "        xx[2,:] = X[2,:] + dt*(X[0,:]*X[1,:] - beta*X[2,:]) + noise_intensity*X[2,:]*sqdt*W[i,:]\n",
    "        X [:,:] = xx[:,:]\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simulate data:\n",
    "\n",
    "* Define a function to simulate observations.\n",
    "\n",
    "* $\\theta = (\\sigma, \\rho, \\beta, \\sigma_{\\text{latent}})$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def simulate_observations(x_0, T, dt, delta, H, R, theta) : \n",
    "    \"\"\"\n",
    "    generate a sequence of observations x_0 : initialization\n",
    "    T = number of observations\n",
    "    delta = time between observations\n",
    "    \"\"\"\n",
    "    m  = np.shape(H)[0]\n",
    "    y  = np.zeros(( m, T ))\n",
    "    X  = np.zeros(( 3, 1 ))\n",
    "    trajectory = np.zeros(( 3, T ))\n",
    "    X[:,0] = x_0\n",
    "    \n",
    "    for t in range(T) :\n",
    "        W = np.random.randn(int(delta/dt),1)\n",
    "        X = propagate_Lorenz63(X, W, dt, delta, theta)\n",
    "        trajectory[:,t] = X[:,0]\n",
    "        y[:,t] = np.dot(H, X[:,0]) + np.random.multivariate_normal(np.zeros(m), R, 1)\n",
    "                        \n",
    "    return y, trajectory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* First define $g$, the error functiom (that is, the density of $Y_t$ given $X_t$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def g(y, X, H, R) :\n",
    "    \n",
    "    E = y - np.transpose(np.dot(H,X))          # denotes error\n",
    "    R_inv = np.linalg.inv(R)\n",
    "    \n",
    "    return np.exp(-0.5*np.diag(np.dot(E, np.dot( R_inv, np.transpose(E) )))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrap particle filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bootstrap_PF(n_particles, x_0, theta, y, dt, delta, g, H, R) :\n",
    "    \n",
    "    scipy.random.seed()\n",
    "    np.random.seed()\n",
    "    \n",
    "    T  = np.shape(y)[1]\n",
    "    n  = len(x_0) \n",
    "    particles = np.zeros(( n, n_particles, T+1 )) \n",
    "    weights   = [1/n_particles]*n_particles \n",
    "    log_NC    = np.zeros(T+1) \n",
    "    for particle in range(n_particles) :\n",
    "        particles[:, particle, 0] = x_0\n",
    "        \n",
    "    # Run the coupled particle filter:\n",
    "    start_time = time.clock()\n",
    "    for t in range(T):\n",
    "        \n",
    "        W = np.random.randn(int(delta/dt),n_particles)\n",
    "        # mutate:\n",
    "        particles[:,:,t+1] = propagate_Lorenz63(particles[:,:,t], W, dt, delta, theta)\n",
    "        weights           *= g(y[:,t], particles[:,:,t+1], H, R)\n",
    "        log_NC[t+1]        = log_NC[t] + np.log(np.sum(weights))\n",
    "        weights           /= np.sum(weights)\n",
    "        \n",
    "        # Resample\n",
    "        if 1/np.sum(weights**2) < 0.5*n_particles :\n",
    "            u = uniform.rvs(0,1,1)\n",
    "            particles[:,:,t+1] = particles[:, systematic_resampling(weights, n_particles, u).astype(int), t+1 ]\n",
    "            weights = [1/n_particles]*n_particles\n",
    "        \n",
    "    return log_NC, particles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutate using same noise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mutate_coupled_PF(particles, theta_values, weights, log_NC, y, dt, delta, g, H, R) :\n",
    "    \n",
    "    scipy.random.seed()\n",
    "    np.random.seed()\n",
    "    \n",
    "    n, n_particles, _ = np.shape(particles)\n",
    "    delta_log_NC = np.zeros(2)\n",
    "    \n",
    "    # propagate forward:\n",
    "    W = np.random.randn(int(delta/dt), n_particles) # The common noise variables used \n",
    "    for i in range(2) :\n",
    "        particles[:,:,i] = propagate_Lorenz63(particles[:,:,i], W, dt, delta, theta_values[:,i])\n",
    "            \n",
    "    # update weights and log-likelihood:\n",
    "    for i in range(2) :\n",
    "        weights[:,i]   *= g(y, particles[:,:,i], H, R)\n",
    "        delta_log_NC[i] = np.log(np.sum(weights[:,i]))\n",
    "        weights[:,i]   /= np.sum(weights[:,i])    \n",
    "        \n",
    "    del W\n",
    "        \n",
    "    return particles, weights, delta_log_NC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coupled resampling function.\n",
    "\n",
    "* Perform adaptive resampling based on ESS. Resample if either of the ESS's (for the two trajectories) falls below a threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def perform_coupled_resampling(particles, weights, coupling_method, \n",
    "                               clambda=50, n_Sinkhorn=50, q=50, uv_threshold=10**10) : \n",
    "    \n",
    "    scipy.random.seed()\n",
    "    np.random.seed()\n",
    "    \n",
    "    n_particles = np.shape(particles)[1]\n",
    "    \n",
    "    c = 0.5\n",
    "    if (1/np.sum(weights[:,0]**2) > c*n_particles)*(1/np.sum(weights[:,1]**2) > c*n_particles) == 0 : \n",
    "        U1, U2 = uniform.rvs(0,1,2)\n",
    "        R = resample(np.transpose(particles[:,:,0]), np.transpose(particles[:,:,1]), \n",
    "                     weights[:,0], weights[:,1], U1, U2, \n",
    "                     coupling_method, clambda, n_Sinkhorn, q, uv_threshold)\n",
    "        \n",
    "        P1, P2, weights[:,0], weights[:,1] = R\n",
    "        particles[:,:,0] = np.transpose(P1)\n",
    "        particles[:,:,1] = np.transpose(P2)\n",
    "                                     \n",
    "    return particles, weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilevel particle filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mutate_MLPF(particles, theta, weights, log_NC, y, dt, delta, g, H, R) :\n",
    "    \n",
    "    scipy.random.seed()\n",
    "    np.random.seed()\n",
    "    \n",
    "    n, n_particles, _ = np.shape(particles)\n",
    "    delta_log_NC = np.zeros(2)\n",
    "    \n",
    "    # propagate forward:\n",
    "    W_f = np.random.randn(int(2*delta/dt), n_particles) # The common noise variables used \n",
    "    W_c = np.sum(np.reshape(W_f, (int(delta/dt),2,n_particles)),axis=1)/np.sqrt(2)\n",
    "    particles[:,:,0] = propagate_Lorenz63(particles[:,:,0], W_f, dt/2, delta, theta)\n",
    "    particles[:,:,1] = propagate_Lorenz63(particles[:,:,1], W_c, dt  , delta, theta)\n",
    "            \n",
    "    # update weights and log-likelihood:\n",
    "    for i in range(2) :\n",
    "        weights[:,i]   *= g(y, particles[:,:,i], H, R)\n",
    "        delta_log_NC[i] = np.log(np.sum(weights[:,i]))\n",
    "        weights[:,i]   /= np.sum(weights[:,i])    \n",
    "        \n",
    "    del W_f, W_c\n",
    "        \n",
    "    return particles, weights, delta_log_NC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MLPF(n_particles, theta, y, x_0, dt, delta, g, H, R, test_function,\n",
    "         coupling_method, clambda=50, n_Sinkhorn=50, q=50, uv_threshold=10**10) : \n",
    "                  \n",
    "    T = np.shape(y)[1] \n",
    "    n = len(x_0) \n",
    "    \n",
    "    particles = np.zeros(( n, n_particles, 2 )) \n",
    "    weights   = np.multiply( np.ones(( n_particles, 2 )), 1/n_particles ) \n",
    "    log_NC    = np.zeros(( 2, T+1 ))  \n",
    "    for particle in range(n_particles) :\n",
    "        for i in range(2) :\n",
    "            particles[:, particle, i] = x_0\n",
    "    test_fn_values = np.zeros(( 2, T ))\n",
    "    running_times = np.zeros(T)\n",
    "            \n",
    "    # Running the particle filter: \n",
    "    \n",
    "    n_delta = delta/dt\n",
    "    start_time = time.clock()\n",
    "    for t in range(T) :\n",
    "        \n",
    "        # Mutate:\n",
    "        M = mutate_MLPF(particles, theta, weights, log_NC[:,t], y[:,t], dt, delta, g, H, R)\n",
    "        \n",
    "        particles, weights = M[0], M[1]\n",
    "        log_NC[:,t+1] = log_NC[:,t] + M[2]\n",
    "\n",
    "        # Resample:\n",
    "        particles, weights = perform_coupled_resampling(particles, weights, coupling_method, \n",
    "                                                        clambda, n_Sinkhorn, q, uv_threshold)\n",
    "        running_times[t] = time.clock() - start_time\n",
    "        for i in range(2) :\n",
    "            test_fn_values[i,t] = np.sum(test_function(particles[:,:,i])*weights[:,i])\n",
    "        \n",
    "    del particles, weights\n",
    "        \n",
    "    return log_NC[:,1:], test_fn_values, running_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Coupled MCMC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlated psuedo-marginal.\n",
    "\n",
    "* Implement the correlated psuedo-marginal method.\n",
    "\n",
    "* First, define a function to drive the two particle systems forward given (correlated) values of the auxiliary variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mutate_MCMC_cpm(particles, weights, log_NC, W_values, theta_values, y, dt, delta, g, H, R) :\n",
    "    \n",
    "    n, n_particles, _ = np.shape(particles)\n",
    "    delta_log_NC = np.zeros(2)\n",
    "    \n",
    "    n_delta = delta/dt\n",
    "    \n",
    "    for i in range(2) :     \n",
    "        #W = W_values[:,j,i]\n",
    "        theta = theta_values[:,i]\n",
    "        particles[:,:,i] = propagate_Lorenz63(particles[:,:,i], W_values[:,:,i], dt, delta, theta)\n",
    "            \n",
    "    for i in range(2) :\n",
    "        weights[:,i]   *= g(y, particles[:,:,i], H, R)\n",
    "        delta_log_NC[i] = np.log(np.sum(weights[:,i]))\n",
    "        weights[:,i]   /= np.sum(weights[:,i])         \n",
    "        \n",
    "    return particles, weights, delta_log_NC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Then define a function to perform a coupled re-sampling given the two (correlated) $U(0,1)$ random variables used for resampling.\n",
    "\n",
    "* Do adaptive resampling. resample if either of the ESS's for the two trajectories falls below a threhold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def coupled_resampling_MCMC_cpm(particles, weights, coupling_method, U1, U2, \n",
    "                                clambda=50, n_Sinkhorn=50, q=50, uv_threshold=10**10) : \n",
    "    \n",
    "    n_particles = np.shape(particles)[1]\n",
    "    \n",
    "    c = 0.5\n",
    "    lambda_final = -100\n",
    "    if (1/np.sum(weights[:,0]**2) > c*n_particles)*(1/np.sum(weights[:,1]**2) > c*n_particles) == 0 : \n",
    "        R = resample(np.transpose(particles[:,:,0]), np.transpose(particles[:,:,1]), \n",
    "                     weights[:,0], weights[:,1], U1, U2, \n",
    "                     coupling_method, clambda, n_Sinkhorn, q, uv_threshold)\n",
    "        \n",
    "        P1, P2, weights[:,0], weights[:,1] = R  \n",
    "        particles[:,:,0] = np.transpose(P1)\n",
    "        particles[:,:,1] = np.transpose(P2)\n",
    "                                           \n",
    "    return particles, weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Then, given values of (correlated) auxiliary variables and parameters, compute the log-likelihoods at the two parameter values using these correlated auxiliary  variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def likelihood_PF_cpm(n_particles, theta_values, W_values, y, x_0, dt, delta, g, H, R,\n",
    "                      coupling_method, clambda=50, n_Sinkhorn=50, q=50, uv_threshold=10**10) : \n",
    "                  \n",
    "    T = np.shape(y)[1] \n",
    "    n = len(x_0) \n",
    "    \n",
    "    particles = np.zeros(( n, n_particles, 2 )) \n",
    "    weights   = np.multiply( np.ones(( n_particles, 2 )), 1/n_particles ) \n",
    "    log_NC    = np.zeros(2)  \n",
    "    for particle in range(n_particles) :\n",
    "        for i in range(2) :\n",
    "            particles[:, particle, i] = x_0\n",
    "\n",
    "    # Running the particle filter: \n",
    "    \n",
    "    n_delta = int(delta/dt)\n",
    "    for t in range(T) :\n",
    "        \n",
    "        # Mutate:\n",
    "        M = mutate_MCMC_cpm(particles, weights, log_NC,\n",
    "                            W_values[ t*n_delta:(t+1)*n_delta, 0:n_particles, : ],\n",
    "                            theta_values, y[:,t], dt, delta, g, H, R)        \n",
    "                \n",
    "        particles, weights = M[0], M[1]\n",
    "        log_NC += M[2]\n",
    "\n",
    "        # Resample:\n",
    "        particles, weights = coupled_resampling_MCMC_cpm(particles, weights,coupling_method,\n",
    "                                                         norm.cdf(W_values[0,-1,0]),\n",
    "                                                         norm.cdf(W_values[0,-1,1]),\n",
    "                                                         clambda, n_Sinkhorn, q, uv_threshold)\n",
    "        \n",
    "    del particles, weights\n",
    "    \n",
    "    return log_NC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Finally, define a function to run the correlated psuedo-marginal method.\n",
    "\n",
    "* Correlate the auxiliary random variables as $W_{n+1} = \\rho\\, W_n + \\sqrt{1-\\rho^2} \\, W$, where $W$ is an array of $N(0,1)$ random variables of the appropriate dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def coupled_PMH_cpm(n_particles, theta_0, y, x_0, prior, n_MCMC, sigma_theta, rho, dt, delta, g, H, R,\n",
    "                    coupling_method, clambda=50, n_Sinkhorn=50, q=50, uv_threshold=10**10) : \n",
    "                \n",
    "    scipy.random.seed()\n",
    "    np.random.seed()\n",
    "    \n",
    "    T    = np.shape(y)[1] \n",
    "    n    = len(x_0) \n",
    "    theta_dim = len(theta_0)\n",
    "    \n",
    "    accept  = 0\n",
    "    N_delta = int(T*delta/dt)\n",
    "    \n",
    "    theta_MCMC_values    = np.zeros((theta_dim, n_MCMC + 1)) \n",
    "    theta_MCMC_values[:,0] = theta_0\n",
    "    W_current        = np.random.randn( N_delta, n_particles+1 ) \n",
    "    \n",
    "    for n in range(n_MCMC) : \n",
    "\n",
    "        theta_current  = theta_MCMC_values[:,n]\n",
    "        theta_proposed = theta_current + sigma_theta*np.random.randn(theta_dim)\n",
    "        \n",
    "        W_proposed = rho*W_current + np.sqrt(1-rho**2)*np.random.randn(  N_delta, n_particles+1 )\n",
    "        W_values   = np.zeros(( N_delta, n_particles+1, 2 ))\n",
    "        W_values[:,:,0] = W_current\n",
    "        W_values[:,:,1] = W_proposed\n",
    "        \n",
    "        theta_values    = np.zeros(( theta_dim, 2 )) \n",
    "        theta_values[:,0] = theta_current\n",
    "        theta_values[:,1] = theta_proposed\n",
    "        \n",
    "        l = likelihood_PF_cpm(n_particles, theta_values, W_values, y, x_0, dt, delta, g, H, R,\n",
    "                              coupling_method, clambda, n_Sinkhorn, q, uv_threshold)\n",
    "        \n",
    "        acceptance_ratio = min(1, prior(theta_proposed)/prior(theta_current)*np.exp(l[1]-l[0]) ) \n",
    "        \n",
    "        u = uniform.rvs(0,1,1)\n",
    "        if u < acceptance_ratio : \n",
    "            theta_current[:] = theta_proposed \n",
    "            W_current[:,:]   = W_proposed\n",
    "            accept          += 1\n",
    "        \n",
    "        del W_proposed, W_values, theta_proposed, theta_values\n",
    "        \n",
    "        theta_MCMC_values[:,n+1] = theta_current\n",
    "    \n",
    "    return theta_MCMC_values, accept/n_MCMC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Same auxiliary variables:\n",
    "\n",
    "* Now define a function to run a coupled MCMC using the same auxiliary variables to calculate the log-likelihoods for each pair $(\\theta, \\theta')$.\n",
    "\n",
    "* This means that at each step of the MCMC, use the same auxiliary variables $W_n$ to calculate the log-likelihoods for the pair $(\\theta_n, \\theta_{\\text{proposed}})$.\n",
    "\n",
    "* The sequence of auxiliary variables $W_0, W_1, \\ldots$ are i.i.d.\n",
    "\n",
    "* First, define a function to calculate the log-likelihood at a pair of $\\theta$-values using the same auxuliary varables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def likelihood_PF_proposed(n_particles, theta_values, y, x_0, dt, delta, g, H, R,\n",
    "                           coupling_method, clambda=50, n_Sinkhorn=50, q=50, uv_threshold=10**10) : \n",
    "                  \n",
    "    T = np.shape(y)[1] \n",
    "    n = len(x_0) \n",
    "    \n",
    "    particles = np.zeros(( n, n_particles, 2 )) \n",
    "    weights   = np.multiply( np.ones(( n_particles, 2 )), 1/n_particles ) \n",
    "    log_NC    = np.zeros(2)  \n",
    "    for particle in range(n_particles) :\n",
    "        for i in range(2) :\n",
    "            particles[:, particle, i] = x_0\n",
    "            \n",
    "    # Running the particle filter: \n",
    "    \n",
    "    n_delta = delta/dt\n",
    "    \n",
    "    for t in range(T) :\n",
    "        \n",
    "        # Mutate:\n",
    "        M = mutate_coupled_PF(particles, theta_values, weights, log_NC, y[:,t], dt, delta, g, H, R)\n",
    "        \n",
    "        particles, weights = M[0], M[1]\n",
    "        log_NC += M[2]\n",
    "\n",
    "        # Resample:\n",
    "        particles, weights = perform_coupled_resampling(particles, weights, coupling_method, \n",
    "                                                        clambda, n_Sinkhorn, q, uv_threshold)\n",
    "        \n",
    "    del particles, weights\n",
    "        \n",
    "    return log_NC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Then define a function to run a coupled MCMC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def coupled_PMH_proposed(n_particles, theta_0, y, x_0, prior, n_MCMC, sigma_theta, dt, delta, g, H, R,\n",
    "                         coupling_method, clambda=50, n_Sinkhorn=50, q=50, uv_threshold=10**10) : \n",
    "                \n",
    "    scipy.random.seed()\n",
    "    np.random.seed()\n",
    "    \n",
    "    T = np.shape(y)[1] \n",
    "    n = len(x_0) \n",
    "    theta_dim = len(theta_0)\n",
    "    \n",
    "    accept  = 0\n",
    "    \n",
    "    theta_MCMC_values      = np.zeros(( theta_dim, n_MCMC + 1 )) \n",
    "    theta_MCMC_values[:,0] = theta_0\n",
    "    \n",
    "    for n in range(n_MCMC) : \n",
    "\n",
    "        theta_current  = theta_MCMC_values[:,n]\n",
    "        theta_proposed = theta_current + sigma_theta*np.random.randn(theta_dim)\n",
    "        \n",
    "        theta_values      = np.zeros(( theta_dim, 2 ))\n",
    "        theta_values[:,0] = theta_current\n",
    "        theta_values[:,1] = theta_proposed\n",
    "        \n",
    "        l = likelihood_PF_proposed(n_particles, theta_values, y, x_0, dt, delta, g, H, R,\n",
    "                                   coupling_method, clambda, n_Sinkhorn, q, uv_threshold)\n",
    "        \n",
    "        acceptance_ratio = min(1, prior(theta_proposed)/prior(theta_current)*np.exp(l[1]-l[0]) ) \n",
    "        \n",
    "        u = uniform.rvs(0,1,1)\n",
    "        if u < acceptance_ratio : \n",
    "            theta_current = theta_proposed \n",
    "            accept       += 1\n",
    "                \n",
    "        theta_MCMC_values[:,n+1] = theta_current\n",
    "    \n",
    "    return theta_MCMC_values, accept/n_MCMC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Representative jumps.\n",
    "\n",
    "* Define a function to calculate the log-likelihoods for a pair $(\\theta, \\theta')$ using the correlated psuedo-marginal method. \n",
    "\n",
    "* That is, when the auxiliary random variables are correlated by $W_2 = \\rho \\, W_1 + \\sqrt{1-\\rho^2} \\, W$, where $W$ is an array of $N(0,1)$ random variables of the appropriate dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def likelihood_cpm(n_particles, theta_values, y, x_0, rho_cpm, dt, delta, g, H, R) :\n",
    "    \n",
    "    scipy.random.seed()\n",
    "    np.random.seed()\n",
    "    \n",
    "    T    = np.shape(y)[1]\n",
    "    n    = len(x_0)\n",
    "    N_delta = int(T*delta/dt) \n",
    "    \n",
    "    W_1 = np.random.randn( N_delta, n_particles+1 ) \n",
    "    W_2 = rho_cpm*W_1 + np.sqrt(1-rho_cpm**2)*np.random.randn( N_delta, n_particles+1 )\n",
    "    \n",
    "    W_values        = np.zeros(( N_delta, n_particles+1, 2 ))\n",
    "    W_values[:,:,0] = W_1\n",
    "    W_values[:,:,1] = W_2\n",
    "    \n",
    "    l = likelihood_PF_cpm(n_particles, theta_values, W_values, y, x_0, dt, delta, g, H, R, 'independent')\n",
    "        \n",
    "    del W_1, W_2, W_values\n",
    "    \n",
    "    return l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a function to calculate variances of some representative jumps.\n",
    "\n",
    "* Consider some representative jumps of the parameter value $\\theta$ for a given proposal density of the MCMC.\n",
    "\n",
    "* These are random jumps obtained from the proposal.\n",
    "\n",
    "* For each representative jump, calculate the variance of the delta log-likelihood using (a) correlated psuedo marginal method, and (b) coupled particle filter with optimal transport resampling and same auxiliary random variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def representative_variances(theta_0, y, x_0, N_particles, rep, n_jumps, sigma_theta, g, H, R,\n",
    "                             rho_cpm, dt, delta, clambda=50, n_Sinkhorn=50, q=50, uv_threshold=10**10) :\n",
    "\n",
    "    scipy.random.seed()\n",
    "    np.random.seed()\n",
    "    \n",
    "    n = len(x_0)\n",
    "    theta_dim = len(theta_0)\n",
    "    \n",
    "    theta_values      = np.zeros((theta_dim, 2) ) \n",
    "    theta_values[:,0] = theta_0\n",
    "\n",
    "    variances = np.zeros(( n_jumps, 2 ))\n",
    "    run_times = np.zeros(2)\n",
    "\n",
    "    delta_loglikelihood = np.zeros(( rep, 2 ))\n",
    "\n",
    "    for n in range(n_jumps) : \n",
    "\n",
    "        scipy.random.seed()\n",
    "        theta_values[0:3,1] = theta_values[0:3,0] + sigma_theta[0:3]*np.random.randn(theta_dim-1)\n",
    "        theta_values[-1 ,1] = np.exp( np.log(theta_values[-1,0]) + sigma_theta[-1]*np.random.randn(1) ) \n",
    "        \n",
    "        start_time = time.clock()\n",
    "        L_proposed = parmap.map(likelihood_PF_proposed, [N_particles[1]]*rep,\n",
    "                                theta_values, y, x_0, dt, delta, g, H, R, \n",
    "                                'OT', clambda, n_Sinkhorn, q, uv_threshold)\n",
    "        \n",
    "        run_times[1] += time.clock() - start_time\n",
    "        \n",
    "        start_time = time.clock()\n",
    "        L_cpm = parmap.map(likelihood_cpm, [N_particles[0]]*rep,\n",
    "                           theta_values, y, x_0, rho_cpm, dt, delta, g, H, R)\n",
    "        \n",
    "        run_times[0] += time.clock() - start_time\n",
    "        \n",
    "        for r in range(rep) :\n",
    "            delta_loglikelihood[r,0] = L_cpm[r][1] - L_cpm[r][0]\n",
    "            delta_loglikelihood[r,1] = L_proposed[r][1] - L_proposed[r][0]\n",
    "            \n",
    "        variances[n,0] = np.var(delta_loglikelihood[:,0])        \n",
    "        variances[n,1] = np.var(delta_loglikelihood[:,1])\n",
    "                \n",
    "    return variances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
