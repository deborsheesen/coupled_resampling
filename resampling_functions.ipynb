{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook contains all the resampling functions used.\n",
    "\n",
    "* Basic ingredients: two particle clouds with two discrete marginal densities.\n",
    "\n",
    "* We use systematic resampling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calling libraries:\n",
    "from __future__ import division \n",
    "import numpy as np\n",
    "import time\n",
    "import math \n",
    "from scipy.sparse import lil_matrix \n",
    "import scipy.spatial as spatial\n",
    "\n",
    "from scipy.sparse import lil_matrix, csr_matrix\n",
    "from scipy.stats import norm, uniform, bernoulli\n",
    "from scipy.linalg import sqrtm \n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* First, define a systematic resampling function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def systematic_resampling(proba_vec, n_particles, U):\n",
    "    \"\"\"\n",
    "    # description:\n",
    "        fast implementation of systematic resampling. Works best when \"proba_vec\" is well balanced\n",
    "    # argument:\n",
    "        proba_vec: a numpy vector representing a probability distribution\n",
    "        U: a sample of a uniform random number\n",
    "        n_particles: number of particles to sample from \"proba_vec\"\n",
    "    # output:\n",
    "        index of the particles that have been resampled\n",
    "    \"\"\"\n",
    "    dim = len(proba_vec)\n",
    "    CS = (np.cumsum(proba_vec) - U / n_particles) * n_particles\n",
    "    CS = np.floor(CS)\n",
    "    CS_jump = np.zeros(dim)\n",
    "    CS_jump[0] = CS[0]+1\n",
    "    CS_jump[1:] = CS[1:] - CS[:-1]\n",
    "    CS_jump = CS_jump.astype(int)\n",
    "    \n",
    "    resampled_particles = np.zeros(n_particles)\n",
    "    n_particles_done = 0\n",
    "    for k in np.unique(CS_jump):\n",
    "        index_jump_k = np.where(CS_jump == k)[0]\n",
    "        nb_of_index_jump_k = len(index_jump_k)\n",
    "        resampled_particles[n_particles_done:(n_particles_done + k*nb_of_index_jump_k)] = np.repeat(index_jump_k,k)\n",
    "        n_particles_done += k*nb_of_index_jump_k\n",
    "    \n",
    "    return(resampled_particles)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Independent resampling \n",
    "\n",
    "* Resample the two particle clouds independently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "X_1 and X_2 are the two particle clouds\n",
    "r and c are the marginals \n",
    "u_1 and u_2 are the U(0,1) random variables used for systematic resampling\n",
    "\"\"\"\n",
    "\n",
    "def independent_resample(X_1, X_2, r, c, u_1, u_2):        \n",
    "    \n",
    "    M = len(r)               # number of particles\n",
    "    X_1 = X_1[systematic_resampling(r, M, u_1).astype(int), :]\n",
    "    X_2 = X_2[systematic_resampling(c, M, u_2).astype(int), :]\n",
    "    \n",
    "    return X_1, X_2, [1/M]*M, [1/M]*M "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximal coupling resampling\n",
    "\n",
    "* Consider the maximal coupling between the two marginals and use this to resample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "particle_cloud_1 and particle_cloud_2 are the two particle clouds\n",
    "weights_1 and weights_2 are the marginals \n",
    "u_1 and u_2 and the U(0,1) random variables used for systematic resampling\n",
    "\"\"\"\n",
    "\n",
    "def maximal_coupling_resample(X_1, X_2, weights_1, weights_2, u_1, u_2) :    \n",
    "    \n",
    "    M, d = np.shape(X_1)\n",
    "    \n",
    "    X_1_resampled = np.zeros(( M, d )) \n",
    "    X_2_resampled = np.zeros(( M, d ))\n",
    "    \n",
    "    weights_min = np.minimum(weights_1,weights_2) \n",
    "    \n",
    "    r = np.arange(0,M) \n",
    "    b = np.random.binomial(n=1, p=np.sum(weights_min), size=M)\n",
    "    \n",
    "    r_1 = r[b>0]; r_2 = r[b==0]\n",
    "    w_min = weights_min/np.sum(weights_min)\n",
    "    \n",
    "    w_1 = (weights_1 - weights_min) / np.sum(weights_1 - weights_min)     \n",
    "    w_2 = (weights_2 - weights_min) / np.sum(weights_2 - weights_min)\n",
    "    \n",
    "    if len(r_1) == 0 :                                       # nothing coupled\n",
    "        X_1_resampled = X_1[systematic_resampling(w_1, M, u_1).astype(int), :]\n",
    "        X_2_resampled = X_2[systematic_resampling(w_2, M, u_2).astype(int), :]\n",
    "    \n",
    "    else:\n",
    "        resampled_index_coupled = systematic_resampling(w_min, len(r_1), u_1).astype(int)\n",
    "        X_1_resampled[r_1,:] = X_1[resampled_index_coupled,:]\n",
    "        X_2_resampled[r_1,:] = X_2[resampled_index_coupled,:]\n",
    "        \n",
    "        if len(r_2) > 0 :                                     # some not coupled\n",
    "            X_1_resampled[r_2,:] = X_1[systematic_resampling(w_1, len(r_2), u_1).astype(int), :] \n",
    "            X_2_resampled[r_2,:] = X_2[systematic_resampling(w_2, len(r_2), u_2).astype(int), :]\n",
    "    \n",
    "    return X_1_resampled, X_2_resampled, [1/M]*M, [1/M]*M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approximate optimal transport resample:\n",
    "\n",
    "* Use Euclidean distance.\n",
    "\n",
    "* Use Sinkhorn iteration.\n",
    "\n",
    "* Dene matrix implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def UVK(u, v, K):\n",
    "    \"\"\"\n",
    "    computes U * K * V\n",
    "    \"\"\"\n",
    "    UU = np.diag(u)\n",
    "    VV = np.diag(v)    \n",
    "    return UU.dot(K.dot(VV))\n",
    "\n",
    "def compute_marginals(C):\n",
    "    return C.sum(axis=0), C.sum(axis=1).flatten()\n",
    "\n",
    "def OT_cost(C, d_matrix, sparse_algebra = False):\n",
    "    if sparse_algebra:\n",
    "        return np.sum( C.multiply(d_matrix))\n",
    "    else:\n",
    "        return np.sum( C * d_matrix)\n",
    "\n",
    "def distance_matrix(X_1, X_2):\n",
    "    dim, ndata = X_1.shape\n",
    "    d_matrix = np.zeros((ndata, ndata))\n",
    "    index_all = np.array(range(ndata))\n",
    "    for k in range(ndata):\n",
    "        d_matrix[index_all, k] = np.sqrt(np.sum( (X_1[:,index_all] - X_2[:,k+np.zeros(ndata).astype(int)])**2, axis = 0))\n",
    "    return d_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Let $d_q$ be the $q$-th percentile of the distance matrix.\n",
    "\n",
    "* We choose $\\lambda$ such that $\\exp(-\\lambda d) = 10^{-c_\\lambda} \\Rightarrow \\lambda = (c_\\lambda \\ln 10) / d_q$.\n",
    "\n",
    "* Keep a threshold for $u$ and $v$, such that, if they cross the threshold then we adjust them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def solve_Sinkhorn_dense(X_1, X_2, r, c, clambda=50, n_Sinkhorn=50, q=50, uv_threshold=10**10):\n",
    "    \n",
    "    ndata = len(r)\n",
    "    u = np.copy(r)\n",
    "    v = np.copy(c)\n",
    "    lambda_iter = 0\n",
    "    \n",
    "    #compute NN and build distance matrix\n",
    "    D_matrix = distance_matrix(X_1, X_2)\n",
    "    \n",
    "    #build K matrix\n",
    "    d = np.percentile(D_matrix, q)\n",
    "    K_matrix = np.exp( -clambda*np.log(10)/d * D_matrix )\n",
    "    \n",
    "    #adaptive sinkhorn iteration\n",
    "    for iteration in range(n_Sinkhorn) :        \n",
    "        #check if u, v hit the threshold\n",
    "        if np.maximum(np.max(u), np.max(v)) > uv_threshold :\n",
    "            #decrease lambda and update K_matrix\n",
    "            clambda = 0.7 * clambda\n",
    "            K_matrix = np.exp( -clambda*np.log(10)/d * D_matrix )\n",
    "            #u /= np.max(u)\n",
    "            #v /= np.max(v)\n",
    "            \n",
    "        #update u and v\n",
    "        u[:] = r / K_matrix.dot(v)\n",
    "        v[:] = c / K_matrix.transpose().dot(u)\n",
    "\n",
    "    C = UVK(u, v, K_matrix)\n",
    "    C = C / np.sum(C)\n",
    "    del D_matrix, K_matrix\n",
    "    \n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" U is the U(0,1) random variable used \"\"\"\n",
    "\n",
    "def OT_systematic_resample(coupling_matrix, U):\n",
    "    \"\"\"\n",
    "    # description:\n",
    "        fast implementation of systematic resampling. Works best when \"proba_vec\" is well balanced\n",
    "    # argument:\n",
    "        coupling_matrix: a 2D matrix representing a probability distribution\n",
    "        U: a sample of a uniform random number\n",
    "    # output:\n",
    "        a list of array: [[array],[array]] containing first/second coordinate of resampled particles\n",
    "    \"\"\"\n",
    "    dim, _ = coupling_matrix.shape\n",
    "    resampled_particles = systematic_resampling(coupling_matrix.ravel(), dim, U)\n",
    "    indices_resampled = [ (resampled_particles // dim).astype(int), (resampled_particles % dim).astype(int) ]\n",
    "    return indices_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def approximate_OT_resample(X_1, X_2, r, c, U, clambda=50, n_Sinkhorn=50, q=50, uv_threshold=10**10) :\n",
    "    \n",
    "    ndata, dim = np.shape(X_1)\n",
    "    coupling_matrix = solve_Sinkhorn_dense(np.transpose(X_1), np.transpose(X_2), \n",
    "                                           r, c, clambda, n_Sinkhorn, q, uv_threshold) \n",
    "    r_indices = OT_systematic_resample(coupling_matrix, U) \n",
    "    \n",
    "    return X_1[r_indices[0],:], X_2[r_indices[1],:], [1/ndata]*ndata, [1/ndata]*ndata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Combined resampling function: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "particle_cloud_1 and particle_cloud_2 are the two particle clouds\n",
    "r and c are the marginals \n",
    "U1 and U2 are the U(0,1) random variables used for systematic resampling\n",
    "\"\"\"\n",
    "\n",
    "def resample(X_1, X_2, r, c, U1, U2, coupling_method, clambda=50, n_Sinkhorn=50, q=50, uv_threshold=10**10) :\n",
    "    \n",
    "    ndata = len(r)\n",
    "    r /= np.sum(r)\n",
    "    c /= np.sum(c)\n",
    "    \n",
    "    lambda_final = -10\n",
    "    lambda_iter  = -1\n",
    "    \n",
    "    if coupling_method == 'independent' :\n",
    "        X_1, X_2, r, c = independent_resample(X_1, X_2, r, c, U1, U2)\n",
    "    \n",
    "    if coupling_method == 'maximal' :\n",
    "        X_1, X_2, r, c = maximal_coupling_resample(X_1, X_2, r, c, U1, U2)\n",
    "        \n",
    "    if coupling_method == 'OT' : \n",
    "        X_1, X_2, r, c = approximate_OT_resample(X_1, X_2, r, c, U1, clambda, n_Sinkhorn, q, uv_threshold)\n",
    "    \n",
    "    return X_1, X_2, r, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
